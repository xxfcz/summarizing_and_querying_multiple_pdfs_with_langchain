{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarizing Multiple PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain\n",
    "# !pip install openai\n",
    "# !pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain import OpenAI, PromptTemplate\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.2)\n",
    "def summarize_pdfs_from_folder(pdfs_folder):\n",
    "    summaries = []\n",
    "    for pdf_file in glob.glob(pdfs_folder + \"/*.pdf\"):\n",
    "        loader = PyPDFLoader(pdf_file)\n",
    "        docs = loader.load_and_split()\n",
    "        chain = load_summarize_chain(llm, chain_type=\"map_reduce\")\n",
    "        summary = chain.run(docs)\n",
    "        print(\"Summary for: \", pdf_file)\n",
    "        print(summary)\n",
    "        print(\"\\n\")\n",
    "        summaries.append(summary)\n",
    "    \n",
    "    return summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_summary(pdf_folder, custom_prompt):\n",
    "    summaries = []\n",
    "    for pdf_file in glob.glob(pdf_folder + \"/*.pdf\"):\n",
    "        loader = PyPDFLoader(pdf_file)\n",
    "        docs = loader.load_and_split()\n",
    "        prompt_template = custom_prompt + \"\"\"\n",
    "\n",
    "        {text}\n",
    "\n",
    "        SUMMARY:\"\"\"\n",
    "        PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
    "        chain = load_summarize_chain(llm, chain_type=\"map_reduce\", \n",
    "                                    map_prompt=PROMPT, combine_prompt=PROMPT)\n",
    "        summary_output = chain({\"input_documents\": docs},return_only_outputs=True)[\"output_text\"]\n",
    "        summaries.append(summary_output)\n",
    "        \n",
    "    return summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary for:  ./pdfs/llm_planning_paper.pdf\n",
      " This paper introduces LLM+P, a framework that combines the strengths of large language models (LLMs) and classical planners to solve long-horizon planning problems. LLM+P takes a natural language description of a problem, converts it into a file written in the planning domain definition language (PDDL), uses classical planners to find a solution, and then translates the solution back into natural language. Experiments on a set of benchmark problems show that LLM+P is able to provide optimal solutions, while LLMs fail to provide even feasible plans. The paper also discusses the limitation of not recognizing when a prompt should be processed by LLM+P, and provides examples of failures of LLM-AS-P and LLM+P.\n",
      "\n",
      "\n",
      "Summary for:  ./pdfs/prompt_vision_language_models_paper.pdf\n",
      "\n",
      "\n",
      "This paper proposes Context Optimization (CoOp), a method for adapting pre-trained vision-language models for downstream image recognition tasks. CoOp models a prompt's context words with learnable vectors while keeping the entire pre-trained parameters fixed. Experiments on 11 datasets show that CoOp can improve the performance of CLIP in few-shot learning tasks and is more efficient than prompt engineering. It is also found to be more robust to domain shifts than zero-shot CLIP and the linear probe model. The paper reviews various methods of prompting, such as natural adversarial examples, scaling up visual and vision-language representation learning, visual prompt tuning, predicting deep zero-shot convolutional neural networks, parameter-efficient prompt tuning, and more.\n",
      "\n",
      "\n",
      "Summary for:  ./pdfs/scaling_transformer_paper.pdf\n",
      " This paper reviews several studies on neural networks and their applications in natural language processing, including the Recurrent Memory Transformer (RMT) which is a new approach to long input text processing in Transformers. RMT can be built upon any model that uses a common supported interface, and its memory requirements grow linearly with input size. The paper also discusses Big Bird, a Transformer model for longer sequences, and Opt, an open pre-trained Transformer language model.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "summaries = summarize_pdfs_from_folder(\"./pdfs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUSTOM_PROMPT = \"Write a concise summary of the following paper with this structure: Problem being solved; Approach; Main results; Main Discussion Points\"\n",
    "# custom_summaries = custom_summary(\"./pdfs\", custom_prompt=CUSTOM_PROMPT)\n",
    "# # Save all summaries into one .txt file\n",
    "# with open(\"custom_summaries.txt\", \"w\") as f:\n",
    "#     for summary in custom_summaries:\n",
    "#         f.write(summary + \"\\n\"*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all summaries into one .txt file\n",
    "with open(\"summaries-xxf.txt\", \"w\") as f:\n",
    "    for summary in summaries:\n",
    "        f.write(summary + \"\\n\"*3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Querying Multiple PDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .py\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.document_loaders import PyPDFDirectoryLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB without persistence: data will be transient\n"
     ]
    }
   ],
   "source": [
    "# Python!\n",
    "loader = PyPDFDirectoryLoader(\"./pdfs/\")\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "# Create the vector store index\n",
    "index = VectorstoreIndexCreator().from_loaders([loader])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" The core idea behind the CoOP paper is to model a prompt's context words with learnable vectors while keeping the entire pre-trained parameters fixed, in order to adapt CLIP-like vision-language models for downstream image recognition tasks.\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is the core idea behind the CoOP (context optimization) paper?\"\n",
    "\n",
    "index.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The central idea is to use the Recurrent Memory Transformer (RMT) architecture to extend the context length of BERT, allowing it to store and process both local and global information across up to 2 million tokens.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is the central idea that can allow for scaling transformers to 1 million tokens?\"\n",
    "\n",
    "index.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' LLM+P takes in a natural language description of a planning problem, then returns a correct (or optimal) plan for solving that problem in natural language. LLM+P does so by first converting the language description into a file written in the planning domain definition language (PDDL), then leveraging classical planners to quickly find a solution, and then translating the found solution back into natural language.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"According to the LLM+P paper, how do you empower large language models with optimal planning profficiency?\"\n",
    "\n",
    "index.query(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
